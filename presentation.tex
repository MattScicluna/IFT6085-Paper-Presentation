\documentclass[10pt]{beamer}

\usetheme[progressbar=frametitle]{metropolis}
\usepackage{appendixnumberbeamer}

\usepackage{booktabs}
\usepackage[scale=2]{ccicons}
\usepackage[english]{babel}

\usepackage{pgfplots}

\usepackage{xspace}
\newcommand{\themename}{\textbf{\textsc{metropolis}}\xspace}

\title{UNDERSTANDING \\ DEEP LEARNING REQUIRES \\ RETHINKING GENERALIZATION}
\date{Feb 21 2018}

\author[shortname]{ Aldo Lamarre \inst{1} \and Matthew C.~Scicluna \inst{2}}
\institute[shortinst]{
\inst{1} D\'epartement d'Informatique et de Recherche Op\'erationnelle\\ Universit\'e de Montr\'eal \and %
\inst{2} Montr\'eal Institute of Learning Algorithms\\
Universit\'e de Montr\'eal}
\titlegraphic{\hfill\includegraphics[height=1.5cm]{MILA.png}}

\begin{document}
	
	\maketitle
	
	\begin{frame}{Table of contents}
		\setbeamertemplate{section in toc}[sections numbered]
		\tableofcontents[hideallsubsections]
	\end{frame}
	
\section{Introduction}

\begin{frame}{Main Question}
	\begin{center}
		\textbf{Main Question}\\
		What distinguishes Neural Networks that generalize well from those that don't?
	\end{center}
	\begin{itemize}
		\item Capacity ?
		\item Regularization ?
		\item How we train the model?
	\end{itemize}
	
\end{frame}	

\begin{frame}{Traditional View}
	
	\begin{figure}
	\centering
		\includegraphics[width=0.7\linewidth]{complexity}
	\caption{Traditional view of generalization. Image taken from \cite{img1}}
	\label{fig:complexity}
	\end{figure}

\end{frame}	

\begin{frame}{Motivation}
\begin{center}
	Why do we care about the problem?
\end{center}
\begin{itemize}
	\item Make neural networks more interpretable
	\item May lead to more principled and reliable model architecture design
\end{itemize}


\end{frame}	

\section{Background}

\begin{frame}{Previous Approaches}
	
We can bound the Generalization Error using measures of complexity such as:
\begin{itemize}
	\item VC Dimension 
	\item Rademacher Complexity
	\item Uniform Stability
\end{itemize}
Additionally, regularization can help (including Early Stopping)
\end{frame}	

\begin{frame}{Related Work}

In 2016 Hardt et al. gives an Upper bound on Generalization error on model using SGD using uniform stability \cite{DBLP:journals/corr/HardtRS15}

\textbf{BUT}

Uniform stability is a property of a learning algorithm and is not affected by the labelling of the training data.

\end{frame}

\begin{frame}{Limitations}
\begin{alertblock}{Main Message}
	Classic results (e.g. PAC bounds) are insufficient in that they cannot distinguish between neural networks with dramatically different generalization performance.
\end{alertblock}

This is demonstrated in the paper \cite{DBLP:journals/corr/ZhangBHRV16}. The central finding:

\begin{center}
	\emph{Deep neural networks easily fit random labels}
\end{center}

\end{frame}	

\section{Results}

\begin{frame}{Experiment}
	\textbf{Setup}: trained several standard architectures on the data with various modifications:
	\begin{enumerate}
		\item True labels $\rightarrow$ No modifications
		\item Random labels $\rightarrow$ randomly changed some labels
		\item shuffled pixels $\rightarrow$ apply some fixed permutation of pixels to all images
		\item Random pixels $\rightarrow$ apply some random permutation of pixels to all images
		\item Gaussian $\rightarrow$ Generate pixels for all images from a Gaussian
	\end{enumerate}

\end{frame}

\begin{frame}{Main Results}
		\begin{figure}
			\centering
		\centering
		\includegraphics[width=\linewidth]{fig1c}
		\caption{Fitting random labels and random pixels on CIFAR10.}
		\label{fig:corruptlabels}
		\end{figure}
\end{frame}

\begin{frame}{Results}
	In most cases, the training error went to zero while test error was high
	
	\begin{alertblock}{Notice:}
		\emph{the model capacity, hyperparameters, and the optimizer remained the same!}
	\end{alertblock}

\end{frame}

\begin{frame}{Results}
	\begin{center}
			\emph{Explicit regularization may improve generalization performance, but is neither necessary nor by itself sufficient for controlling generalization error}
	\end{center}

	\begin{figure}
		\centering
		\centering
		\includegraphics[width=\linewidth]{fig2c}
		\label{fig:withreg}
	\end{figure}
\end{frame}

\section{Technical dive}

%\begin{frame}{Technical dive }
%	Some definitions:
%	\begin{itemize}
%		\item \textbf{Representational Capacity}: A models ability to fit a wide variety of functions:
%		\item \textbf{Effective Capacity}: The functions that the Learning Algorithm is capable of learning e.g. imperfection of optimization algorithm.
%	\end{itemize}
%\end{frame}	
\begin{frame}{Finite-sample expressivity }
The empirical observations are complemented with a theoretical construction
showing that generically large neural networks can express any labelling of the training
data.
\pause
\begin{block}{Definition} Finite-sample expressivity : is the expressive power of neural networks on a
finite sample of size n.
\end{block}
\small
NB : It is possible to transfer population level results to finite sample results
using uniform convergence theorems.
\end{frame}	
\begin{frame}{Finite-sample expressivity }
%Theorem 1.
\begin{block}{Theorem}
There exists\footnote{NOT all networks satisfy this} a two-layer neural network with ReLU activations and $2n+d$
weights that can represent any function on a sample of size $n$ in $d$ dimensions.
\end{block}
\end{frame}	
\begin{frame}{Proof }
\begin{block}{Lemma 1}
For any two interleaving sequences of n real numbers $b_1 < x_1 < b_2 < x_2 \dots < b_n < x_n$
, the $n \times n$ matrix $A = [max \{x_i - b_j,0\}]_{ij}$ has full rank. Its smallest eigenvalue is
$min_i\{ x_i - b_i\}$
\end{block}

	%What is an interesting analytical technique, proof method, experimental protocol, other approach to doing things? What is one technical thing that we can learn here? Explain in a few slides.
	
	
\end{frame}	
\begin{frame}{Proof}
%Theorem 1.
For weight vectors $w, b \in R^n$ and $a \in R^d$, consider the function $c : R^n \to R$,
\[c(x) =\sum \limits_{j=1}w_j\, max\{a^Tx - b_j , 0\}\]
\only<2->{
\begin{itemize}
\item \only<2>{ This can be done trivially with a depth 2 neural network with relu. }

\only<3,5>{Now, fixing a sample $S = {z_1, \dots , z_n}$ of size n and a target vector $y \in  R_n$. We
	need to find weights $a, b,w $ so that $y_i = c(z_i)$ for all $i \in \{1, \dots , n\}$
}
\only<4>{ First, choose a and b such that with $\xi_i = a^Tz_i$ we have the interleaving property $b_1 < x_1 < b_2 <
	\dots < b_n < x_n$ %This is possible since all zi’s are distinct. 
	Next, consider the set of n equations in the $n$ unknowns $w$, \[y_i = c(z_i) , i \in \{1, \dots , n\}\]
	We have $c(z_i) = Aw$, where $A = [max\{\xi_i - b_i, 0\}]_{ij}$ is the matrix of Lemma 1.}
\only<5>{\item We chose $a$ and $b$ so that the lemma applies and hence $A$ has full rank. We can now solve the linear
	system $y = Aw$ to find suitable weights w.}
\end{itemize}
}

\end{frame}	
\section{Discussion}
\begin{frame}{What We Were Talking About... }
	To recap:
	\begin{enumerate}
		\item We just showed that generically large neural networks can express any labelling of the training data
		\item And so it is not surprising to see the networks learn the training data perfectly
		\item but it is surprising that we can't explain this well!
	\end{enumerate}
\end{frame}

\begin{frame}{Some Thoughts... }
	\begin{enumerate}
		\item Our favourite papers are the ones that shed light on truths that are taken for granted.
		\item Its obvious that randomizing the labels would eliminate generalizability, but finding precise mathematical statements about this is not!
		\item Models used in practice have the capability of memorizing the training data. Is it somehow easier not to?
		\item The interplay between generalization and ease of optimization seems like an interesting thing to explore...
	\end{enumerate}
	%What is not convincing? (too strong assumptions? results not as ‘good’/‘tight’ as other approaches we might know? results are not applicable for ‘x’ reason? bounds are vacuous?)
	
	%What can be improved? (if you where to work in this area, which part of the result would you tweak to make it better, non-vacuous, tighter, more relevant...)
	
	%What interesting open questions that might have been outside the scope of this paper come to your mind when studying it?
\end{frame}	

{\setbeamercolor{palette primary}{fg=black, bg=cyan}
	\begin{frame}[standout]
		Any Questions?
	\end{frame}
}

\begin{frame}{References}
\bibliography{presentation}
\bibliographystyle{ieeetr}
\end{frame}	
	
\end{document}



